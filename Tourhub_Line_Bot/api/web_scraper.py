import requests
import logging
from bs4 import BeautifulSoup
import re

logger = logging.getLogger(__name__)

def scrape_leaderboard_data():
    """å¾ TourHub ç¶²ç«™æŠ“å–æ’è¡Œæ¦œè³‡æ–™"""
    try:
        url = "https://tourhub-ashy.vercel.app/"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # æŸ¥æ‰¾æ’è¡Œæ¦œè³‡æ–™
        leaderboard_data = {}
        rank_colors = {1: "#FFD700", 2: "#C0C0C0", 3: "#CD7F32", 4: "#4ECDC4", 5: "#FF6B9D"}
        rank_titles = {1: "ğŸ¥‡ ç¬¬ä¸€å", 2: "ğŸ¥ˆ ç¬¬äºŒå", 3: "ğŸ¥‰ ç¬¬ä¸‰å", 4: "ğŸ… ç¬¬å››å", 5: "ğŸ–ï¸ ç¬¬äº”å"}
        
        # å˜—è©¦å¤šç¨®é¸æ“‡å™¨ä¾†æ‰¾åˆ°æ’è¡Œæ¦œé …ç›®
        selectors = [
            '.leaderboard-item',
            '.ranking-item', 
            '.trip-item',
            '[class*="rank"]',
            '[class*="leaderboard"]',
            '.card',
            '.item'
        ]
        
        items = []
        for selector in selectors:
            items = soup.select(selector)
            if items:
                logger.info(f"æ‰¾åˆ° {len(items)} å€‹é …ç›®ä½¿ç”¨é¸æ“‡å™¨: {selector}")
                break
        
        if not items:
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç‰¹å®šçš„æ’è¡Œæ¦œé …ç›®ï¼Œå˜—è©¦æŸ¥æ‰¾æ‰€æœ‰åŒ…å«è¡Œç¨‹è³‡è¨Šçš„å…ƒç´ 
            items = soup.find_all(['div', 'article', 'section'], 
                                 text=re.compile(r'(è¡Œç¨‹|æ—…éŠ|æ—¥æœ¬|æ±äº¬|å¤§é˜ª|åŒ—æµ·é“)', re.I))
            logger.info(f"ä½¿ç”¨æ–‡æœ¬åŒ¹é…æ‰¾åˆ° {len(items)} å€‹é …ç›®")
        
        # è§£ææ‰¾åˆ°çš„é …ç›®
        for i, item in enumerate(items[:5], 1):
            try:
                # å˜—è©¦æå–è¡Œç¨‹æ¨™é¡Œ
                title_element = (
                    item.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']) or
                    item.find(class_=re.compile(r'title|name|heading', re.I)) or
                    item.find(['span', 'div'], text=re.compile(r'.+', re.I))
                )
                
                title = "æœªçŸ¥è¡Œç¨‹"
                if title_element:
                    title = title_element.get_text(strip=True)
                    # æ¸…ç†æ¨™é¡Œ
                    title = re.sub(r'^ç¬¬?\d+å?[ï¼š:]?\s*', '', title)
                    title = re.sub(r'[ğŸ¥‡ğŸ¥ˆğŸ¥‰ğŸ…ğŸ–ï¸]', '', title)
                
                # å˜—è©¦æå–åœ°å€è³‡è¨Š
                area = "æœªçŸ¥åœ°å€"
                area_keywords = ['æ—¥æœ¬', 'æ±äº¬', 'å¤§é˜ª', 'äº¬éƒ½', 'åŒ—æµ·é“', 'æ²–ç¹©', 'åå¤å±‹', 'ç¦å²¡']
                for keyword in area_keywords:
                    if keyword in title:
                        area = keyword
                        break
                
                # å˜—è©¦æå–å¤©æ•¸è³‡è¨Š
                duration = "æœªçŸ¥å¤©æ•¸"
                duration_match = re.search(r'(\d+)å¤©', title + str(item))
                if duration_match:
                    days = int(duration_match.group(1))
                    duration = f"{days}å¤©{days-1}å¤œ" if days > 1 else "1å¤©"
                
                leaderboard_data[str(i)] = {
                    "rank": i,
                    "title": title,
                    "rank_title": rank_titles.get(i, f"ğŸ–ï¸ ç¬¬{i}å"),
                    "color": rank_colors.get(i, "#9B59B6"),
                    "destination": area,
                    "duration": duration,
                    "participants": f"{10-i*2}äººæ”¶è—",  # æ¨¡æ“¬æ”¶è—æ•¸
                    "feature": "ç²¾å½©è¡Œç¨‹",
                    "itinerary": f"è¡Œç¨‹ï¼š{title}\nåœ°å€ï¼š{area}\nå¤©æ•¸ï¼š{duration}",
                    "favorite_count": 10-i*2,
                    "share_count": 5-i,
                    "view_count": 50-i*10,
                    "popularity_score": round(0.2-i*0.03, 2)
                }
                
            except Exception as e:
                logger.error(f"è§£æç¬¬ {i} å€‹é …ç›®æ™‚å‡ºéŒ¯: {e}")
                continue
        
        # å¦‚æœæ²’æœ‰æŠ“å–åˆ°è³‡æ–™ï¼Œä½¿ç”¨é è¨­è³‡æ–™
        if not leaderboard_data:
            logger.warning("æœªèƒ½å¾ç¶²ç«™æŠ“å–åˆ°è³‡æ–™ï¼Œä½¿ç”¨é è¨­è³‡æ–™")
            leaderboard_data = get_default_leaderboard_data()
        
        logger.info(f"æˆåŠŸæŠ“å– {len(leaderboard_data)} ç­†æ’è¡Œæ¦œè³‡æ–™")
        return leaderboard_data
        
    except Exception as e:
        logger.error(f"æŠ“å–ç¶²ç«™è³‡æ–™å¤±æ•—: {e}")
        return get_default_leaderboard_data()

def scrape_trip_details(rank):
    """å¾ç¶²ç«™æŠ“å–ç‰¹å®šæ’åçš„è©³ç´°è¡Œç¨‹"""
    try:
        url = "https://tourhub-ashy.vercel.app/"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # æŸ¥æ‰¾è©³ç´°è¡Œç¨‹è³‡æ–™
        # å˜—è©¦æ‰¾åˆ°ç¬¬ rank å€‹è¡Œç¨‹çš„è©³ç´°è³‡è¨Š
        detail_selectors = [
            f'.trip-detail-{rank}',
            f'[data-rank="{rank}"]',
            '.trip-details',
            '.itinerary',
            '.schedule'
        ]
        
        details_element = None
        for selector in detail_selectors:
            details_element = soup.select_one(selector)
            if details_element:
                break
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç‰¹å®šçš„è©³ç´°è³‡è¨Šï¼Œç”Ÿæˆæ¨¡æ“¬çš„è©³ç´°è¡Œç¨‹
        rank_titles = {1: "ğŸ¥‡ ç¬¬ä¸€å", 2: "ğŸ¥ˆ ç¬¬äºŒå", 3: "ğŸ¥‰ ç¬¬ä¸‰å", 4: "ğŸ… ç¬¬å››å", 5: "ğŸ–ï¸ ç¬¬äº”å"}
        rank_colors = {1: "#FFD700", 2: "#C0C0C0", 3: "#CD7F32", 4: "#4ECDC4", 5: "#FF6B9D"}
        
        # æ ¹æ“šæ’åç”Ÿæˆä¸åŒçš„è¡Œç¨‹
        trip_templates = {
            1: {
                "title": "åŒ—æµ·é“å¤å­£æ¸…æ¶¼ä¹‹æ—…",
                "area": "åŒ—æµ·é“",
                "itinerary": [
                    "2025å¹´08æœˆ15æ—¥ (æ˜ŸæœŸäº”)\n10:00 - 18:00 æœ­å¹Œå¸‚å€ãƒ»å¤§é€šå…¬åœ’",
                    "2025å¹´08æœˆ16æ—¥ (æ˜ŸæœŸå…­)\n09:00 - 17:00 å°æ¨½é‹æ²³ãƒ»éŸ³æ¨‚ç›’å ‚",
                    "2025å¹´08æœˆ17æ—¥ (æ˜ŸæœŸæ—¥)\n09:00 - 16:00 å¯Œè‰¯é‡è–°è¡£è‰ç”°",
                    "2025å¹´08æœˆ18æ—¥ (æ˜ŸæœŸä¸€)\n08:30 - 17:30 ç¾ç‘›é’æ± ãƒ»ç™½é¬šç€‘å¸ƒ",
                    "2025å¹´08æœˆ19æ—¥ (æ˜ŸæœŸäºŒ)\n10:00 - 21:00 å‡½é¤¨å±±å¤œæ™¯ãƒ»æœå¸‚",
                    "2025å¹´08æœˆ20æ—¥ (æ˜ŸæœŸä¸‰)\n09:30 - 16:30 ç™»åˆ¥åœ°ç„è°·ãƒ»ç†Šç‰§å ´",
                    "2025å¹´08æœˆ21æ—¥ (æ˜ŸæœŸå››)\n10:00 - 15:00 æ–°åƒæ­²æ©Ÿå ´å•†åœˆ"
                ]
            },
            2: {
                "title": "å¤§é˜ªç¾é£Ÿæ–‡åŒ–ä¹‹æ—…",
                "area": "å¤§é˜ª",
                "itinerary": [
                    "2025å¹´08æœˆ01æ—¥ (æ˜ŸæœŸäº”)\n09:00 - 16:00 å¤§é˜ªåŸãƒ»å¤©å®ˆé–£",
                    "2025å¹´08æœˆ02æ—¥ (æ˜ŸæœŸå…­)\n08:30 - 21:00 ç’°çƒå½±åŸ",
                    "2025å¹´08æœˆ03æ—¥ (æ˜ŸæœŸæ—¥)\n11:00 - 20:00 é“é “å €ãƒ»å¿ƒé½‹æ©‹",
                    "2025å¹´08æœˆ04æ—¥ (æ˜ŸæœŸä¸€)\n10:00 - 17:00 é»‘é–€å¸‚å ´ãƒ»é€šå¤©é–£"
                ]
            },
            3: {
                "title": "æ±äº¬ä¸‰æ—¥éŠ",
                "area": "æ±äº¬",
                "itinerary": [
                    "2025å¹´07æœˆ20æ—¥ (æ˜ŸæœŸæ—¥)\n09:00 - 18:00 æ·ºè‰å¯ºãƒ»é›·é–€",
                    "2025å¹´07æœˆ21æ—¥ (æ˜ŸæœŸä¸€)\n10:00 - 20:00 æ¾€è°·ãƒ»åŸå®¿",
                    "2025å¹´07æœˆ22æ—¥ (æ˜ŸæœŸäºŒ)\n09:30 - 17:00 æ±äº¬è¿ªå£«å°¼æ¨‚åœ’"
                ]
            }
        }
        
        template = trip_templates.get(rank, {
            "title": f"ç¬¬{rank}åç²¾å½©è¡Œç¨‹",
            "area": "æ—¥æœ¬",
            "itinerary": [f"Day 1: ç²¾å½©è¡Œç¨‹é–‹å§‹", f"Day 2: æ›´å¤šç²¾å½©æ™¯é»"]
        })
        
        result = {
            "rank": rank,
            "rank_title": rank_titles.get(rank, f"ğŸ–ï¸ ç¬¬{rank}å"),
            "title": template["title"],
            "color": rank_colors.get(rank, "#9B59B6"),
            "area": template["area"],
            "itinerary": "\n\n".join(template["itinerary"]),
            "itinerary_list": template["itinerary"]
        }
        
        logger.info(f"æˆåŠŸç”Ÿæˆç¬¬{rank}åçš„è©³ç´°è¡Œç¨‹")
        return result
        
    except Exception as e:
        logger.error(f"æŠ“å–ç¬¬{rank}åè©³ç´°è¡Œç¨‹å¤±æ•—: {e}")
        return None

def get_default_leaderboard_data():
    """é è¨­çš„æ’è¡Œæ¦œè³‡æ–™"""
    rank_colors = {1: "#FFD700", 2: "#C0C0C0", 3: "#CD7F32", 4: "#4ECDC4", 5: "#FF6B9D"}
    rank_titles = {1: "ğŸ¥‡ ç¬¬ä¸€å", 2: "ğŸ¥ˆ ç¬¬äºŒå", 3: "ğŸ¥‰ ç¬¬ä¸‰å", 4: "ğŸ… ç¬¬å››å", 5: "ğŸ–ï¸ ç¬¬äº”å"}
    
    default_trips = [
        {"title": "åŒ—æµ·é“å¤å­£æ¸…æ¶¼ä¹‹æ—…", "area": "åŒ—æµ·é“", "duration": "7å¤©6å¤œ"},
        {"title": "å¤§é˜ªç¾é£Ÿæ–‡åŒ–ä¹‹æ—…", "area": "å¤§é˜ª", "duration": "4å¤©3å¤œ"},
        {"title": "æ±äº¬ä¸‰æ—¥éŠ", "area": "æ±äº¬", "duration": "6å¤©5å¤œ"},
        {"title": "æ—¥æœ¬æ±äº¬äº”æ—¥éŠ", "area": "æ—¥æœ¬", "duration": "3å¤©2å¤œ"},
        {"title": "æ±äº¬ç²¾å½©è¡Œç¨‹", "area": "æ±äº¬", "duration": "15å¤©14å¤œ"}
    ]
    
    leaderboard_data = {}
    for i, trip in enumerate(default_trips, 1):
        leaderboard_data[str(i)] = {
            "rank": i,
            "title": trip["title"],
            "rank_title": rank_titles.get(i, f"ğŸ–ï¸ ç¬¬{i}å"),
            "color": rank_colors.get(i, "#9B59B6"),
            "destination": trip["area"],
            "duration": trip["duration"],
            "participants": f"{12-i*2}äººæ”¶è—",
            "feature": "ç²¾å½©è¡Œç¨‹",
            "itinerary": f"è¡Œç¨‹ï¼š{trip['title']}\nåœ°å€ï¼š{trip['area']}\nå¤©æ•¸ï¼š{trip['duration']}",
            "favorite_count": 12-i*2,
            "share_count": 6-i,
            "view_count": 60-i*10,
            "popularity_score": round(0.18-i*0.03, 2)
        }
    
    return leaderboard_data
