import requests
import logging
from bs4 import BeautifulSoup
import re

logger = logging.getLogger(__name__)

def scrape_leaderboard_data():
    """å¾ TourHub ç¶²ç«™æŠ“å–æ’è¡Œæ¦œè³‡æ–™ï¼ˆç„¡æ¨¡æ“¬å…§å®¹ï¼‰"""
    try:
        url = "https://tourhub-ashy.vercel.app/"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # æŸ¥æ‰¾æ’è¡Œæ¦œè³‡æ–™
        leaderboard_data = {}
        rank_colors = {1: "#FFD700", 2: "#C0C0C0", 3: "#CD7F32", 4: "#4ECDC4", 5: "#FF6B9D"}
        rank_titles = {1: "ğŸ¥‡ ç¬¬ä¸€å", 2: "ğŸ¥ˆ ç¬¬äºŒå", 3: "ğŸ¥‰ ç¬¬ä¸‰å", 4: "ğŸ… ç¬¬å››å", 5: "ğŸ–ï¸ ç¬¬äº”å"}
        
        # å˜—è©¦å¤šç¨®é¸æ“‡å™¨ä¾†æ‰¾åˆ°æ’è¡Œæ¦œé …ç›®
        selectors = [
            '.leaderboard-item',
            '.ranking-item', 
            '.trip-item',
            '[class*="rank"]',
            '[class*="leaderboard"]',
            '.card',
            '.item'
        ]
        
        items = []
        for selector in selectors:
            items = soup.select(selector)
            if items:
                logger.info(f"æ‰¾åˆ° {len(items)} å€‹é …ç›®ä½¿ç”¨é¸æ“‡å™¨: {selector}")
                break
        
        if not items:
            logger.warning("æœªæ‰¾åˆ°æ’è¡Œæ¦œé …ç›®")
            return {}
        
        # è§£ææ‰¾åˆ°çš„é …ç›®
        for i, item in enumerate(items[:5], 1):
            try:
                # å˜—è©¦æå–è¡Œç¨‹æ¨™é¡Œ
                title_element = (
                    item.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']) or
                    item.find(class_=re.compile(r'title|name|heading', re.I)) or
                    item.find(['span', 'div'], text=re.compile(r'.+', re.I))
                )
                
                title = None
                if title_element:
                    title = title_element.get_text(strip=True)
                    # æ¸…ç†æ¨™é¡Œ
                    title = re.sub(r'^ç¬¬?\d+å?[ï¼š:]?\s*', '', title)
                    title = re.sub(r'[ğŸ¥‡ğŸ¥ˆğŸ¥‰ğŸ…ğŸ–ï¸]', '', title)
                
                # å˜—è©¦æå–åœ°å€è³‡è¨Š
                area = None
                area_keywords = ['æ—¥æœ¬', 'æ±äº¬', 'å¤§é˜ª', 'äº¬éƒ½', 'åŒ—æµ·é“', 'æ²–ç¹©', 'åå¤å±‹', 'ç¦å²¡']
                if title:
                    for keyword in area_keywords:
                        if keyword in title:
                            area = keyword
                            break
                
                # å˜—è©¦æå–å¤©æ•¸è³‡è¨Š
                duration = None
                duration_match = re.search(r'(\d+)å¤©', (title or '') + str(item))
                if duration_match:
                    days = int(duration_match.group(1))
                    duration = f"{days}å¤©{days-1}å¤œ" if days > 1 else "1å¤©"
                
                leaderboard_data[str(i)] = {
                    "rank": i,
                    "title": title or "",
                    "rank_title": rank_titles.get(i, f"ç¬¬{i}å"),
                    "color": rank_colors.get(i, "#9B59B6"),
                    "destination": area or "",
                    "duration": duration or "",
                }
                
            except Exception as e:
                logger.error(f"è§£æç¬¬ {i} å€‹é …ç›®æ™‚å‡ºéŒ¯: {e}")
                continue
        
        logger.info(f"æˆåŠŸæŠ“å– {len(leaderboard_data)} ç­†æ’è¡Œæ¦œè³‡æ–™")
        return leaderboard_data
        
    except Exception as e:
        logger.error(f"æŠ“å–ç¶²ç«™è³‡æ–™å¤±æ•—: {e}")
        return {}

def scrape_trip_details(rank):
    """å¾ç¶²ç«™æŠ“å–ç‰¹å®šæ’åçš„è©³ç´°è¡Œç¨‹ï¼ˆç„¡æ¨¡æ“¬å…§å®¹ï¼‰"""
    try:
        url = "https://tourhub-ashy.vercel.app/"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # æŸ¥æ‰¾è©³ç´°è¡Œç¨‹è³‡æ–™
        # å˜—è©¦æ‰¾åˆ°ç¬¬ rank å€‹è¡Œç¨‹çš„è©³ç´°è³‡è¨Š
        detail_selectors = [
            f'.trip-detail-{rank}',
            f'[data-rank="{rank}"]',
            '.trip-details',
            '.itinerary',
            '.schedule'
        ]
        
        details_element = None
        for selector in detail_selectors:
            details_element = soup.select_one(selector)
            if details_element:
                break
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç‰¹å®šçš„è©³ç´°è³‡è¨Šï¼Œç›´æ¥è¿”å› None
        if not details_element:
            logger.warning(f"æœªæ‰¾åˆ°ç¬¬{rank}åçš„è©³ç´°è¡Œç¨‹å…ƒç´ ")
            return None

        # å˜—è©¦æ‹†å‡ºå¤šè¡Œæ–‡å­—
        text = details_element.get_text("\n", strip=True)
        itinerary_lines = [line for line in text.split("\n") if line.strip()]

        rank_titles = {1: "ğŸ¥‡ ç¬¬ä¸€å", 2: "ğŸ¥ˆ ç¬¬äºŒå", 3: "ğŸ¥‰ ç¬¬ä¸‰å", 4: "ğŸ… ç¬¬å››å", 5: "ğŸ–ï¸ ç¬¬äº”å"}
        rank_colors = {1: "#FFD700", 2: "#C0C0C0", 3: "#CD7F32", 4: "#4ECDC4", 5: "#FF6B9D"}

        result = {
            "rank": rank,
            "rank_title": rank_titles.get(rank, f"ç¬¬{rank}å"),
            "title": "",
            "color": rank_colors.get(rank, "#9B59B6"),
            "area": "",
            "itinerary": "\n\n".join(itinerary_lines),
            "itinerary_list": itinerary_lines
        }

        logger.info(f"æˆåŠŸæŠ“å–ç¬¬{rank}åçš„è©³ç´°è¡Œç¨‹æ–‡å­—ï¼Œå…± {len(itinerary_lines)} è¡Œ")
        return result
        
    except Exception as e:
        logger.error(f"æŠ“å–ç¬¬{rank}åè©³ç´°è¡Œç¨‹å¤±æ•—: {e}")
        return None

## å·²ç§»é™¤é è¨­æ’è¡Œæ¦œæ¨¡æ“¬è³‡æ–™
