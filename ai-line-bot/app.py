import os
import asyncio
import time
from functools import lru_cache
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *
from openai import OpenAI
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# LINE è¨­å®š
LINE_CHANNEL_ACCESS_TOKEN = os.getenv('CHANNEL_ACCESS_TOKEN')
LINE_CHANNEL_SECRET = os.getenv('CHANNEL_SECRET')
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
line_handler = WebhookHandler(LINE_CHANNEL_SECRET)

# OpenAI GPT è¨­å®š
openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# åˆå§‹åŒ– Flask
app = Flask(__name__)

# ç°¡å–®çš„å¿«å–æ©Ÿåˆ¶
response_cache = {}

@app.route("/", methods=["GET"])
def index():
    return "âœ… LINE Bot on Vercel is running."

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature', '')
    body = request.get_data(as_text=True)

    print("ğŸ“© Received callback from LINE")
    print("ğŸ“¦ Body:", body)

    try:
        line_handler.handle(body, signature)
    except InvalidSignatureError:
        print("âŒ Invalid Signature")
        abort(400)

    return 'OK'

@line_handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    print("âœ… webhook message received")
    process_text_message(event)

def get_cached_response(user_text):
    """æª¢æŸ¥å¿«å–ä¸­æ˜¯å¦æœ‰ç›¸åŒçš„å›æ‡‰"""
    return response_cache.get(user_text)

def cache_response(user_text, response):
    """å¿«å–å›æ‡‰"""
    if len(response_cache) > 100:  # é™åˆ¶å¿«å–å¤§å°
        response_cache.clear()
    response_cache[user_text] = response

def process_text_message(event):
    user_text = event.message.text.strip()
    user_id = event.source.user_id

    # å¿«é€Ÿå›è¦†å¸¸è¦‹å•é¡Œ
    quick_responses = {
        "æ’è¡Œæ¦œ": "ğŸ“Š æ­¤åŠŸèƒ½å°šæœªå®Œå–„ï¼Œæ•¬è«‹æœŸå¾…å¾ŒçºŒæ›´æ–°ï¼",
        "ä½ å¥½": "ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯æ‚¨çš„æ™ºæ…§åŠ©ç†ï¼Œæœ‰ä»€éº¼å¯ä»¥å¹«åŠ©æ‚¨çš„å—ï¼Ÿ",
        "å¹«åŠ©": "ğŸ¤– æˆ‘å¯ä»¥å›ç­”æ‚¨çš„å•é¡Œã€æä¾›è³‡è¨Šï¼Œæˆ–èˆ‡æ‚¨èŠå¤©ã€‚è«‹ç›´æ¥è¼¸å…¥æ‚¨çš„å•é¡Œï¼",
        "hi": "ğŸ‘‹ Hi! æˆ‘æ˜¯æ‚¨çš„æ™ºæ…§åŠ©ç†ï¼Œæœ‰ä»€éº¼å¯ä»¥å¹«åŠ©æ‚¨çš„å—ï¼Ÿ",
        "hello": "ğŸ‘‹ Hello! æˆ‘æ˜¯æ‚¨çš„æ™ºæ…§åŠ©ç†ï¼Œæœ‰ä»€éº¼å¯ä»¥å¹«åŠ©æ‚¨çš„å—ï¼Ÿ",
        "è¬è¬": "ğŸ˜Š ä¸å®¢æ°£ï¼å¾ˆé«˜èˆˆèƒ½å¹«åŠ©åˆ°æ‚¨ï¼",
        "å†è¦‹": "ğŸ‘‹ å†è¦‹ï¼æœ‰éœ€è¦éš¨æ™‚æ‰¾æˆ‘èŠå¤©å–”ï¼"
    }
    
    # æª¢æŸ¥æ˜¯å¦æœ‰å¿«é€Ÿå›è¦†
    if user_text in quick_responses:
        reply_text = quick_responses[user_text]
    else:
        # æª¢æŸ¥å¿«å–
        cached_response = get_cached_response(user_text)
        if cached_response:
            reply_text = cached_response
            print("âœ… ä½¿ç”¨å¿«å–å›æ‡‰")
        else:
            try:
                # å„ªåŒ–çš„ OpenAI API èª¿ç”¨
                start_time = time.time()
                response = openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",  # å¯ä»¥æ”¹ç‚º gpt-3.5-turbo-16k æˆ– gpt-4-turbo
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ LINE æ©Ÿå™¨äººä¸­çš„æ™ºæ…§åŠ©ç†ï¼Œè«‹ç°¡æ½”æ˜ç­åœ°å›ç­”å•é¡Œï¼Œå›æ‡‰é•·åº¦æ§åˆ¶åœ¨100å­—ä»¥å…§ã€‚"},
                        {"role": "user", "content": user_text}
                    ],
                    max_tokens=100,  # é€²ä¸€æ­¥é™åˆ¶å›æ‡‰é•·åº¦ä»¥æé«˜é€Ÿåº¦
                    temperature=0.5,  # é™ä½å‰µé€ æ€§ä»¥æé«˜ä¸€è‡´æ€§
                    timeout=8,  # ç¸®çŸ­è¶…æ™‚æ™‚é–“
                    stream=False  # é—œé–‰ä¸²æµä»¥ç²å¾—å®Œæ•´å›æ‡‰
                )
                reply_text = response.choices[0].message.content.strip()
                end_time = time.time()
                print(f"â±ï¸ API å›æ‡‰æ™‚é–“ï¼š{end_time - start_time:.2f}ç§’")
                
                # å¿«å–å›æ‡‰
                cache_response(user_text, reply_text)
                
            except Exception as e:
                print(f"âš ï¸ OpenAI API éŒ¯èª¤ï¼š{str(e)}")
                reply_text = "æŠ±æ­‰ï¼Œæˆ‘ç¾åœ¨ç„¡æ³•å›æ‡‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

    try:
        line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))
    except Exception as e:
        print("âš ï¸ æ¨é€å›è¦†è¨Šæ¯å¤±æ•—ï¼š", e)

# æœ¬åœ°æ¸¬è©¦
if __name__ == "__main__":
    app.run(port=8080)
